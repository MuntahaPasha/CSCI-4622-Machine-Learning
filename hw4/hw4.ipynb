{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02804d34b749993749a391fe95bd7520",
     "grade": false,
     "grade_id": "cell-39cc69ad672c2457",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 4: SVM\n",
    "\n",
    "\n",
    "This assignment is due on Moodle by **11:59pm on Friday October 30**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://github.com/BoulderDS/CSCI5622-Machine-Learning/blob/master/info/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda (Version: 2019.07) with Python 3.7. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "- In this homework you will explore the primal and dual representations of support vector machines, as well as the performance of various kernels while classifying sentiments. Install the following packages: `nltk` (Version: 3.5), `scikit-learn` (Version: 0.23.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6a65990e3ee338fcca6169ba1c4d1ff",
     "grade": false,
     "grade_id": "cell-42609c0d44322df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Please put your name and cuidentity username.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Muntaha Pasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identity Key**: mupa0444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for deterministic output\n",
    "np.random.seed(5622)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcadea9323aaa669deed90d8c5ea2f4b",
     "grade": false,
     "grade_id": "cell-1e40b611c0a33948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[40 Points] Problem 1 - Basic concepts of SVM\n",
    "---\n",
    "\n",
    "### Part 1 [10 points]\n",
    "* What are the main differences between the primal and the dual representations?\n",
    "* For the variables $\\xi_i$, $C$ in the primal formation, what are their roles? Write out the upper/lower bounds (constraints) of these variables. What are the interpretation for these maximum/minimum values?\n",
    "* For the variable $\\alpha_i$, $\\beta_i$ in the dual formation, what are the upper/lower bound (constraints) of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (Understanding Primal/Dual Formation) https://www.quora.com/What-is-primal-and-dual-formulation-in-SVM\n",
    "\n",
    "2 - (More on SVM) http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture6.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f616bf5ea6cd25ba5b9bbbf94bb465f5",
     "grade": true,
     "grade_id": "cell-f177349aed9aabcf",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "-  $\\textbf{What are the main differences between the primal and the dual representations?}$\n",
    "\n",
    "For a $\\textbf{Primal Representation}$, we are going to optimize the function $min_{w, b} = \\frac{1}{2} ||w||^2$, which is subject to $y_i \\cdot (w \\cdot x_i + b) \\geq 1$ for all $i \\in [1, m]$. We will get an optimal value for $w$, however there will be an unknown in regards to $\\alpha_i$. To classify any sort of point we would need to use the equation $w^Tx$ (where $x$ is the point) which could be costly especially if our $d$ value is very big. Another way to look at it is in the Primal Representation, we are going to minimize the objective function with respect to $w, b$, and $x_i$ where we would be directly solving for our variables $b$ and for $w$. $\\checkmark$\n",
    "\n",
    "On the other hand now, a $\\textbf{Dual Representation}$ we will get an $\\alpha_i$ for the places where $\\alpha_i = 0$, and as we discussed that would be everywhere except where the support vectors are. In this representation, we are maximixing a different objective function with regard to $\\alpha$. We want to maximize $ max_\\alpha \\sum_{i=1}^m \\alpha_i -\\frac{1}{2} \\sum_{i = 1}^m\\sum_{j = 1}^m\\alpha_i \\cdot \\alpha_j \\cdot y_i \\cdot y_j(x_j \\cdot x_i)$ which is subject to $\\alpha_i \\ge 0$, $i \\in[1, m]$, $\\sum_{i} \\alpha_i \\cdot y_i = 0$. This Objective Function doesn't deal with $b$, or $w$, and only makes use of $\\alpha$. Through it, we find the max $\\alpha$ value and then would use KKT conditions to figure out what our $w$ and $b$ are. $\\checkmark$\n",
    "\n",
    "- $\\textbf{For the variables $\\xi_i$, $C$ in the primal formation, what are their roles? Write out the upper/lower bounds (constraints) of these variables. What are the interpretation for these maximum/minimum values?}$\n",
    "\n",
    "We know that $\\xi_i$ is what defines the slack variables, which is the level of how incorrectly a point is from where it should be. We also know that $\\xi_i$ has to always be $\\ge 0$. We can break this up into two cases.\n",
    "\n",
    "1. If $y_i(w \\cdot x_i + b)\\ge 1$, then $\\xi_i = 0$. (The margin is satisfied)\n",
    "\n",
    "So when some point $x_i$ is within the scope of our margin, a slack variable isn't needed so $\\xi_i$ will just be 0.\n",
    "\n",
    "2. $\\xi_i$ = $1-y_i(w \\cdot x_i+b)$. (Margin isn't satisfied)\n",
    "\n",
    "In this case, when you have some point $x_i$ that doesn't satisfy the margin and is found within the opposite area of where it should be, then $\\xi_i$ must be equal to $1-y_i(w \\cdot x_i+b)$.\n",
    "\n",
    "$C$ is our variable that defines the trade-off between slack and margin points. We know that $C$ will always be $\\ge 0$. An we also know that if we increase the value of $C$, the margin is also going to increase in turn, which leads to a decrease in bias, increase in variance, and therefore a decrease in the overall overfitting. $\\checkmark$\n",
    "\n",
    "- $\\textbf{For the variable $\\alpha_i$, $\\beta_i$ in the dual formation, what are the upper/lower bound (constraints) of them?}$\n",
    "\n",
    "$\\alpha_i$ is always going to be $\\ge 0$, and its also a non-zero value for our Support Vectors. However, for the other vectors that don't impact the weight $(w)$, then it's just going to be $0$. In a Soft Margin SVM, we learned in lecture that the bounds of $\\alpha_i$ are going to be between $C$ and $0$. $C \\ge \\alpha_i \\ge 0$.\n",
    "\n",
    "Now, looking at $\\beta_i$, we can also see that $\\beta_i$ is always going to be $\\ge 0$. In a Soft Margin SVM, we learned in lecture that the bounds of $\\beta_i$ are going to be between $C$ and $0$. $C\\ge\\beta_i\\ge0$. \n",
    "\n",
    "We can put $\\alpha_i$ and $\\beta_i$ together to make $C$, because ($\\alpha_i + \\beta_i = C$). We know that when $\\alpha_i = 0$, then $\\beta_i = C$ and on the reverse of that when $\\alpha_i = C$, then $\\beta_i = 0$. We can also relate $\\xi_i$ to $\\alpha_i$ given that $\\beta_i \\xi_i = 0$ which tells us that our $\\beta_i = 0$, or that $\\xi_i = 0$. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9711d8637903ea332d20ecae46de997",
     "grade": false,
     "grade_id": "cell-fe7878b1dd2ff1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [20 points]\n",
    "\n",
    " * Given a weight vector, implement the `find_support` function that returns the indices of the support vectors.\n",
    " * Given a weight vector, implement the `find_slack` function that returns the indices of the vectors with nonzero slack.\n",
    " * Given the alpha dual vector, implement the `weight_vector` function that returns the corresponding weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (Slack in SVM) https://cel.archives-ouvertes.fr/cel-01003007/file/Lecture3_Linear_SVM_with_Slack.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03db7fcb00d613cbf64708dc2a27b9ab",
     "grade": false,
     "grade_id": "cell-14c104d96c00c2eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.kINSP = np.array([\n",
    "            (1, 8, +1),\n",
    "            (7, 2, -1),\n",
    "            (6, -1, -1),\n",
    "            (-5, 0, +1),\n",
    "            (-5, 1, -1),\n",
    "            (-5, 2, +1),\n",
    "            (6, 3, +1),\n",
    "            (6, 1, -1),\n",
    "            (5, 2, -1)\n",
    "        ])\n",
    "        self.kSEP = np.array([\n",
    "            (-2, 2, +1),    # 0 - A\n",
    "            (0, 4, +1),     # 1 - B\n",
    "            (2, 1, +1),     # 2 - C\n",
    "            (-2, -3, -1),   # 3 - D\n",
    "            (0, -1, -1),    # 4 - E\n",
    "            (2, -3, -1),    # 5 - F\n",
    "        ])\n",
    "\n",
    "\n",
    "    def weight_vector(self, x, y, alpha):\n",
    "        \"\"\"\n",
    "        Given a vector of alphas, compute the primal weight vector w.\n",
    "        The vector w should be returned as an Numpy array.\n",
    "        \n",
    "        Returns:\n",
    "            w (np.ndarray): The primal weight vector w.\n",
    "        \"\"\"\n",
    "\n",
    "        w = np.zeros(len(x[0]))\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        counter = 0\n",
    "        lenX = len(x[0])\n",
    "        #Iterate over x\n",
    "        while(counter < lenX):\n",
    "            for i in range(len(x)):\n",
    "                #Updat x, y, and alpha, and set weight\n",
    "                xVal = x[i][counter]\n",
    "                yVal = y[i]\n",
    "                alph = alpha[i]\n",
    "                #Here we compute our w.\n",
    "                w[counter] = (w[counter]) + (xVal * yVal * alph) \n",
    "            counter = counter + 1\n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "    def find_support(self, x, y, w, b, tolerance=0.001):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all of the support vectors as a set.\n",
    "        \n",
    "        Returns:\n",
    "            support (set) : set of support vector indices\n",
    "        \"\"\"\n",
    "\n",
    "        support = set()\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        lenX = len(x)\n",
    "        for i in range(lenX):\n",
    "            inner = (x[i].dot(w) + b)\n",
    "            mult = y[i] * inner\n",
    "            toleranceOther = (1 - tolerance)\n",
    "            toleranceAdd = (1 + tolerance)\n",
    "            #Check to see if the conditions apply.\n",
    "            if mult <= toleranceAdd and mult >= toleranceOther:\n",
    "                support.add(i)\n",
    "        return support\n",
    "\n",
    "\n",
    "\n",
    "    def find_slack(self, x, y, w, b):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all examples with nonzero slack as a set.\n",
    "        \n",
    "        Returns:\n",
    "            slack (set) : set of slack indices \n",
    "        \"\"\"\n",
    "\n",
    "        slack = set()\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        lenX = len(x)\n",
    "        for i in range(lenX):\n",
    "            #Calculating our slack variable\n",
    "            inner = (x[i].dot(w) + b)\n",
    "            mult = y[i] * inner\n",
    "            if mult < 1:\n",
    "                slack.add(i)\n",
    "        return slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3aa73cc220bc2b16c09b0e72ebd10dfa",
     "grade": true,
     "grade_id": "cell-3c7d7f432578009e",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TestWideSlack (tests.tests.TestSVM) ... ok\n",
      "TestNarrowSlack (tests.tests.TestSVM) ... ok\n",
      "TestSupport (tests.tests.TestSVM) ... ok\n",
      "TestWeight (tests.tests.TestSVM) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite(\"prob 1\", SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b842153bbb481e2a662612aaa95c8979",
     "grade": false,
     "grade_id": "cell-7c25ab5ed0d77621",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [10 points]\n",
    "\n",
    "The goal of this problem is to correctly classify test data points, given a training data set.\n",
    "For this problem, assume that we are training an SVM with a quadratic kernel, which means our kernel function is a polynomial kernel of degree 2. You are given the data set presented in the figure below. The slack penalty $C$ will determine the location of the decision boundary.\n",
    "\n",
    "Justify the following questions in a sentence or via drawing decision boundary.\n",
    "![training_data](./data/data.png)\n",
    "\n",
    "* Where would the decision boundary be for very large values of $C$ ?\n",
    "* Where you would expect the decision boundary to be if  $C = 0$ ?\n",
    "* Which of the two cases above would you expect to generalize better on test data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (C Value in SVMs) https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel#:~:text=The%20C%20parameter%20tells%20the,the%20training%20points%20classified%20correctly.\n",
    "\n",
    "2 - (More about C Value in SVM) https://medium.com/@pushkarmandot/what-is-the-significance-of-c-value-in-support-vector-machine-28224e852c5a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "985db05b9496fb3714ee2096479f6f7d",
     "grade": true,
     "grade_id": "cell-02406ba497be1623",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "- Where would the decision boundary be for very large values of $C$ ?\n",
    "\n",
    "For very large values of $C$, we would expect our decision boundary to be closer to one of our classes above because bigger and bigger $C$ values try and seperate positive class and negative class points in a way that we would not have misclassification. The margin would no longer be maximized in this case, as it aims for no misclassification. $\\checkmark$\n",
    "\n",
    "- Where you would expect the decision boundary to be if  $C = 0$ ?\n",
    "\n",
    "If $C$ was equal to $0$, we would find the decision boundary right in the middle of both classes, with a misclassification on our $2$ red points. That's because when $C$ equals $0$, our $\\xi_i$ variable can take on larger values. We will allow for a few bad apples here in this case. Margin will be thus maximized here because of that case. $\\checkmark$\n",
    "\n",
    "\n",
    "- Which of the two cases above would you expect to generalize better on test data? Why?\n",
    "\n",
    "I would say that Case $2$ will generalize better on Test Data because we run the risk of overfitting on the training data from Case $1$. This is because in Case $1$, our margin would be very narrow, and not maximized. So we would get a high training accuracy, but in turn we'd get a low test accuracy. Meanwhile with Case $2$, as we discussed in the answer above, it allows for a few bad apples, so we would be okay with a few misclassifications thus maximizing our Margin which is what we want for our SVM. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bef866dff5b0ce6c9dea5e7aea37f23a",
     "grade": false,
     "grade_id": "cell-55888810e6151283",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[30 points] Problem 2 - The Kernel Trick\n",
    "---\n",
    "The kernel trick can make SVM powerful and become non-linear. In this problem we will get familiar with the kernel trick.\n",
    "\n",
    "### Part 1 [10 points]\n",
    "\n",
    "We will construct a support vector machine that computes the XOR function, using values of +1 and −1 (instead of 1 and 0) for both inputs and outputs, so that an example looks like ($[−1, 1], 1$) or ($[−1, −1], −1$). \n",
    "- Map the input $[x_1, x_2]$ into a space consisting of $x_1$ and $x_1x_2$. \n",
    "- Plot the four input points in this space, and the maximal margin separator. \n",
    "- Give the margin value in the markdown cell. \n",
    "\n",
    "Remember to indicate which points have output +1 and which -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (Plotting w/ Ax) https://www.geeksforgeeks.org/matplotlib-axes-axes-plot-in-python/\n",
    "\n",
    "2 - (Numpy Linspace) https://www.geeksforgeeks.org/numpy-linspace-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0fe2b7a9339f72690a8459981899a23",
     "grade": true,
     "grade_id": "cell-20ea52b04bb94dee",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2794dc7aee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "#-----------------------SetUp & Definitions-----------------------\n",
    "x_1 = [-1, -1, 1, 1]\n",
    "x_2 = [-1, 1, -1, 1]\n",
    "y_val = [-1, 1, 1, -1]\n",
    "lenY = len(y_val)\n",
    "c1 = {1 : 'green', -1 : 'red'}\n",
    "c2 = {1 : 'lime', -1 : 'pink'}\n",
    "\n",
    "#-----------------------XOR w/o Kernel Setup----------------------\n",
    "fig1, ax = plt.subplots(figsize = (10, 7))\n",
    "for i in range(lenY):\n",
    "    #Label for the legend, showing what numbers are being XOR'd and what the result is.\n",
    "    labelAx = str(x_1[i]) + \" xor \" + str(x_2[i]) + \" = \" + str(y_val[i])\n",
    "    #Plot x1, x2 in their respective colors.\n",
    "    ax.scatter(x_1[i], x_2[i], label = labelAx, color = c1[y_val[i]])\n",
    "ax.set_title(\"XOR before Kernel Trick\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize = 15)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize = 15)\n",
    "ax.legend()\n",
    "\n",
    "#----------------------XOR with Kernel Setup----------------------\n",
    "fig1, ax1 = plt.subplots(figsize = (10, 7))\n",
    "for i in range(lenY):\n",
    "    #Label for the legend, showing what numbers are being XOR'd and what the result is.\n",
    "    #This time we are doing x1 * x2\n",
    "    labelAx1 = str(x_1[i]) + \" xor \" + str(x_1[i] * x_2[i]) + \" = \" + str(y_val[i])\n",
    "    #Plot x1, x1*x2 in their respective colors.\n",
    "    ax1.scatter(x_1[i], (x_1[i] * x_2[i]), label = labelAx1, color = c2[y_val[i]])\n",
    "#Make sure they have same shape (of 4)\n",
    "ax1.plot(x_1, np.linspace(0, 0, 4), label = \"Maximal Margin Separator\")\n",
    "ax1.set_title(\"XOR after Kernel Trick\")\n",
    "ax1.set_xlabel(\"$x_1$\", fontsize = 15)\n",
    "ax1.set_ylabel(\"($x_1 \\cdot x_2$)\", fontsize = 15)\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e73071136adefa9aed2ebcd5957bd69a",
     "grade": true,
     "grade_id": "cell-64bbc4980b5c4edd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "The Margins we get will be at $x_1 \\cdot x_2 = 1$, and at $x_1 \\cdot x_2 = -1$. Our $\\textbf{Maximal Margin Seperator}$ as shown above in my second plot is going to be at $x_1 \\cdot x_2 = 0$. You can see it perfectly splits the data. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "387213f9cb504ea0e2fc596e89d0f919",
     "grade": false,
     "grade_id": "cell-5ba884cd7e49d78d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [5 points]\n",
    "Plot the separating line of **Part 1** back in the original Euclidean input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6e323e18881c3d6be9b1ff2abd3d8ac",
     "grade": true,
     "grade_id": "cell-9020bbe03ed87cfc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2794deceaf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "#-----------------------SetUp & Definitions-----------------------\n",
    "x_1 = [-1, -1, 1, 1]\n",
    "x_2 = [-1, 1, -1, 1]\n",
    "y_val = [-1, 1, 1, -1]\n",
    "listShape = []\n",
    "for i in range(100):\n",
    "    listShape.append(i*0)\n",
    "Shape = np.linspace(-1, 1, 100)\n",
    "lenY = len(y_val)\n",
    "c3 = {1 : 'limegreen', -1 : 'magenta'}\n",
    "\n",
    "#--------------------Orig Euclidean Input Space-------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for i in range(lenY):\n",
    "    #Label for the legend, showing what numbers are being XOR'd and what the result is.\n",
    "    labelAx = str(x_1[i]) + \" xor \" + str(x_2[i]) + \" = \" + str(y_val[i])\n",
    "    #Plot x1, x2 in their respective colors.\n",
    "    ax.scatter(x_1[i], x_2[i], label = labelAx, color = c3[y_val[i]])\n",
    "#Earlier Part\n",
    "ax.plot(Shape, listShape, label = \"Maximal Margin Seperator\")\n",
    "#Plot\n",
    "ax.plot(listShape, Shape)\n",
    "ax.set_title(\"Seperating Line for Original Euclidean Input Space (Part 1)\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize = 15)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize = 15)\n",
    "ax.legend(loc = \"upper center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d978690256991b3b10176a46bb25febe",
     "grade": false,
     "grade_id": "cell-3013de14effe2d4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [5 points]\n",
    "Is the separator in **Part 1** linear? Is the one in **Part 2** linear? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8821f5382c580de24c483bd1a0cd4b31",
     "grade": true,
     "grade_id": "cell-119e16472d287f4e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "Our Seperator from Part 1 is $\\textbf{is Linear}$, and our Seperator from Part 2 is $\\textbf{Non-Linear}$. When the Seperator is used in the context of our Original Euclidian Input Space, then we get that when $x_1 = 0$ or $x_2 = 0$ or $x_1 = 0$ & $x_2 = 0$, then $x_1 \\cdot x_2 = 0$, which then makes a hyper-plane that is $\\textbf{Non-Linear}$ that seperates the points where $y = - 1$ from those where $y = + 1$. All of this goes to show we can use Kernel Tricks to classify the data where it otherwise would not be linearly seperable. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95b20466fd3ca86119c013f75bc4656f",
     "grade": false,
     "grade_id": "cell-b8218f37ba88f7c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4 [10 points]\n",
    "The key point of the so-called “kernel trick” in SVMs is to learn a classifier that effectively separates the training data in a higher dimensional space without having to explicitly compute the representation $\\phi(\\mathbf{x})$ of every point $\\mathbf{x}$ in the original input space. Instead, all the work is done through the kernel function $K(\\mathbf{x}_i, \\mathbf{x}_i)$, for example, we can use $K(\\mathbf{x}_i, \\mathbf{x}_i) = \\phi(\\mathbf{x}_i)\\phi(\\mathbf{x}_j)$.\n",
    "\n",
    "Show how to compute the squared Euclidean distance in the projected space between any two points $\\mathbf{x}_i$, $\\mathbf{x}_j$ in the original space without explicitly computing the $\\phi$ mapping, instead using the kernel function $K$. In other words, derive $d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j))$ into a form using only the kernel function.\n",
    "\n",
    "Please remember to simplify your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3beedd96d39e9c464377ae2885f78ba0",
     "grade": true,
     "grade_id": "cell-c6b6512e7d992202",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "We can write out the derivative as such.\n",
    "\n",
    "$d(\\phi(x_i), \\phi(x_j)) = (\\phi(x_i) - \\phi(x_j))^2$\n",
    "\n",
    "Using the Chain-Rule, we get...\n",
    "\n",
    "$d(\\phi(x_i), \\phi(x_j)) = (\\phi(x_i))^2 + (\\phi(x_j)^2 - 2 (\\phi(x_i) (\\phi(x_j))$\n",
    "\n",
    "We can write out the square terms seperately and subtract the Kernel Function at the end.\n",
    "\n",
    "$d(\\phi(x_i), \\phi(x_j)) = ((\\phi(x_i)(\\phi(x_i)) + ((\\phi(x_j)(\\phi(x_j)) - 2K(x_i, x_j)$\n",
    "\n",
    "Now we can write this all out in terms of $K$. We use $K$ on the $x_i$ and $x_j$'s, and keep in that subtraction we needed in the above step.\n",
    "\n",
    "$d(\\phi(x_i), \\phi(x_j)) = K(x_i, x_i) + K(x_j, x_j) - 2K(x_i, x_j)$\n",
    "\n",
    "From this last step, we can see that $d(\\phi(x_i), \\phi(x_j))$ will be derived using the Kernel Function ($K$), and we don't need to exactly calculate the mapping for each $x$ with $\\phi$. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eda0db6d3653c96ec72059179ddb52ec",
     "grade": false,
     "grade_id": "cell-2a7361023bfbbe84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[30 points] Problem 3 - SVM with `sklearn`\n",
    "---\n",
    "\n",
    "In this problem, you will get familiar with important practical functions in scikit-learn such as pipeline, grid search, and cross validation. You will experiment with these using support vector machines.\n",
    "\n",
    "Note that grid search can take some time on your laptop, so make sure that your code is correct with a small subset of the training data and search a reasonable number of options.\n",
    "\n",
    "* Use the Sklearn implementation of support vector machines to train a classifier to distinguish Positive and negative sentiments\n",
    "* Experiment with linear, polynomial, and RBF kernels. First, perform a GridSearch over each kernel function and a small set of parameters defined over a wide range to help narrow down the search space.\n",
    "* Then choose the best performing kernel from your coarse scale search and define a narrower set of parameters for random search to further optimize the hyperparameters. Comment on the experiments you ran and optimal hyperparameters you found.\n",
    "Hint: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "* Evaluate classification performance for each model for optimal parameters by testing on a hold-out set.\n",
    "\n",
    "Following is a dataset containing reviews and sentiments associated with it.\n",
    "\n",
    "We will create a SVM Classifier to predict positive or negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sizes] train: 4000, test: 1000\n",
      "[Avg S] train: 0.49875, test: 0.505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "reviews  = pd.read_csv('./data/reviews.csv')\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=5622)\n",
    "X_train = train['reviews']\n",
    "X_test = test['reviews']\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']\n",
    "\n",
    "# Print some data info\n",
    "print(f'[Sizes] train: {len(X_train)}, test: {len(X_test)}')\n",
    "print(f'[Avg S] train: {sum(y_train)/len(X_train)}, test: {sum(y_test)/len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\munta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "# download nltk data\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = set(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3824735b35e2893522e59b8f68ebf486",
     "grade": false,
     "grade_id": "cell-c5af7b0df4f72c74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 1 [5 points]\n",
    "\n",
    "Complete the `get_vectorizer` and `get_kfolds` functions below.\n",
    "\n",
    "- Use [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to vectorize reviews as dictionary of term frequencies.\n",
    "- Define the crossvalidation split using [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "196749f1263ab6c54cc354afa9b5c4c3",
     "grade": false,
     "grade_id": "cell-ab58d371c35713b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    \"\"\"\n",
    "    Separate text into tokens\n",
    "    \"\"\"\n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def get_vectorizer():\n",
    "    \"\"\" \n",
    "    \n",
    "    Create and return a CountVectorizer\n",
    "    \n",
    "    Hints:\n",
    "        Read docs on CountVectorizer to set arguments (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) \n",
    "        Pass the above tokenize function as the tokenizer.\n",
    "        Use en_stopwords variable above as stopwords\n",
    "        \n",
    "        Play with different parameters.\n",
    "        min_df argument can help with generalizability\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #We want to put our tokenizer, and make use of the en_stopwords into vecotrizer\n",
    "    vectorizer = CountVectorizer(tokenizer = tokenize, stop_words = en_stopwords)\n",
    "    return vectorizer\n",
    "\n",
    "def get_kfolds():\n",
    "    \"\"\" \n",
    "    Split dataset into 5 splits using StratifiedKFold \n",
    "    \n",
    "    Hint:\n",
    "    Remember to shuffle\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #We want shuffle, 5 splits, and random state as none\n",
    "    kfolds = StratifiedKFold(n_splits = 5, random_state = None, shuffle = True)\n",
    "    return kfolds\n",
    "\n",
    "\n",
    "vectorizer = get_vectorizer()\n",
    "kfolds = get_kfolds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fabfb15f1d4ee78f5d2f9aa72193a59",
     "grade": true,
     "grade_id": "cell-7b9737faea74ccef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for grading; please ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75b3eb30df1712dcef3a3334c4f4c8b8",
     "grade": false,
     "grade_id": "cell-ddb76d3c6bae8e15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [10 points]\n",
    "* Create a pipeline with our `CountVectorizer` object in **Part 1** and an SVM Classifier.\n",
    "* Create and fit a `GridSearchCV` object with the following parameter values:\n",
    "  * Linear kernel, $C = 0.01, 1.0, 10.0$\n",
    "  * Polynomial kernel, $\\text{degree} = 2, 3$, $\\gamma = 0.1, 0.5, 1$\n",
    "  * RBF kernel, $\\gamma = 0.1, 0.5, 1$\n",
    "* Report accuracy on the best estimator from our `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8d29528eda0679df9787ebc7a3d812e",
     "grade": false,
     "grade_id": "cell-a3dd5b25a9ce8feb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(**kwargs):\n",
    "    \"\"\"\n",
    "        Define pipeline using make_pipeline (see sklearn docs) with vectorizer and SVM Classifier. \n",
    "        \n",
    "        The SVM Classifer should take in all kwargs passed (passing kwargs can be achieved with fn(**kwargs))\n",
    "        You should use balanced class weights for SVM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #Put the argument get vectorizer into pipeline, put in lass weight balanced and pass kwargs\n",
    "    pipeline_svm = make_pipeline(get_vectorizer(), SVC(**kwargs, class_weight = 'balanced'))\n",
    "    return pipeline_svm\n",
    "\n",
    "def get_course_params():\n",
    "    \"\"\"\n",
    "        Create the grid search parameters defined above for course grid search. \n",
    "        Returns a list of dictionaries to be passed as argument to GridSearchCV below\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #param_grid = [{'kernel': ['linear'], 'C': [0.01, 1.0 ,10]},{'kernel': ['polynomial'], 'degree': [2,3], 'gamma' : [0.1, 0.5, 1], \n",
    "    #'C': [0.01, 1.0 ,10]}, {'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [0.01, 1.0 ,10]}]\n",
    "    #Setting up my parameter grid with the correct paramaters needed and correct values\n",
    "    param_grid = [{'svc__kernel': ['rbf'], 'svc__gamma': [0.1, 0.5, 1.0]},\n",
    "                    {'svc__kernel': ['linear'], 'svc__C':[0.01, 1.0, 10.0]},\n",
    "                    {'svc__kernel': ['poly'], 'svc__degree': [2, 3], 'svc__gamma': [0.1, 0.5, 1.0]}]\n",
    "    return param_grid\n",
    "\n",
    "def get_grid_svm():\n",
    "    \"\"\"\n",
    "        Create GridSearchCV with pipeline and the grid search parameters given above using \"accuracy\" for scoring.\n",
    "    \"\"\" \n",
    "     \n",
    "    param_grid = get_course_params()\n",
    "    pipeline_svm = get_pipeline()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #Call Grid Search and give it pipeline svm, param grid, and make sure scoring is set correctly.\n",
    "    grid_svm = GridSearchCV(pipeline_svm, param_grid, scoring='accuracy')\n",
    "    return grid_svm\n",
    "    \n",
    "    \n",
    "\n",
    "grid_svm = get_grid_svm()\n",
    "# For debugging purposes, it makes sense to use a smaller set of training set to speed up the grid search progress\n",
    "# refit is not necessary since by default refit is true in GridSearchCV, \n",
    "# but we did this to show that you need to use the best parameter to fit the whole training set\n",
    "_ = grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68a1aabe495c06e761fe8f6ce92d667f",
     "grade": true,
     "grade_id": "cell-fb57090849f1d094",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8819e90ae6a2708015ffaa2865cfd394",
     "grade": false,
     "grade_id": "cell-47833f7ec14a9d22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'svc__C': 0.01, 'svc__kernel': 'linear'} | best cv score: 0.8745\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_score = None\n",
    "\n",
    "# Store best parameters and CV score from grid search for reporting into the variables above\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "best_params = grid_svm.best_params_\n",
    "best_score = grid_svm.best_score_\n",
    "\n",
    "# Report best parameters and CV score from grid search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf1df17e0bfe9499ed65aeda57e96c8c",
     "grade": true,
     "grade_id": "cell-1268040b2d1a98b4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef3c4187f1be7404dd2fb775bb68dea1",
     "grade": false,
     "grade_id": "cell-a561071b8ec246bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [10 points]\n",
    "\n",
    "Choose the best performing kernel and parameter values from your coarse scale grid search and use them to set up a narrower range of parameter values. We will use randomized grid search to sample a fixed number of these candidate parameter sets for cross validation. The number of sampled parameter sets `n_iter` provides a trade-off between computational cost and quality of the \"optimal\" parameters. Feel free to experiment with different values of this parameter, but please change it back to `n_iter = 5` before submitting your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a05d6ba748a96b7b451774b54a41134",
     "grade": true,
     "grade_id": "cell-e1116a343a3e645a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munta\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.1s remaining:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.4s finished\n"
     ]
    }
   ],
   "source": [
    "def get_params_fine_scale():\n",
    "    \"\"\"\n",
    "        Set param_grid to a dictionary containing parameter values for fine scale search.\n",
    "        Return value is passed as argument to RandomizedSearchCV below\n",
    "    \"\"\" \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    #Linear was the best kernel outcome I achieved, and lowering the value will make it better\n",
    "    #We know 1 has to be better than 10, and so 0.01 is a good point to do it at.\n",
    "    param_grid = [{'svc__kernel': ['linear'], 'svc__C': [0.01]}]\n",
    "    return param_grid\n",
    "\n",
    "def get_random_svm():\n",
    "    \"\"\"\n",
    "        Create randomized parameter search over fine scale grid;\n",
    "        Do NOT change the value of n_iter in the submitted version of your notebook.\n",
    "    \"\"\" \n",
    "    n_iter = 5\n",
    "    pipeline_svm = get_pipeline()\n",
    "    param_grid = get_params_fine_scale()\n",
    "\n",
    "    random_svm = RandomizedSearchCV(\n",
    "        pipeline_svm,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv = kfolds,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=1,   \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return random_svm\n",
    "\n",
    "random_svm = get_random_svm()\n",
    "# refit is not necessary since by default refit is true in RandomSearchCV, \n",
    "# but we did this to show that you need to use the best parameter to fit the whole training set\n",
    "_ = random_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "125f0f9cacebf47639d09fd315e2c960",
     "grade": false,
     "grade_id": "cell-39b5a8b9e508cf0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'svc__kernel': 'linear', 'svc__C': 0.01} | best cv score: 0.877\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_score = None\n",
    "\n",
    "# Store best parameters and score from random search for reporting into the variables above \n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "#Using the random.svm functions to find the best score and parameters.\n",
    "best_score = random_svm.best_score_\n",
    "best_params = random_svm.best_params_\n",
    "\n",
    "# Report best parameters and score from random search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ef3b52d32ae25d6d538048785d9e88",
     "grade": true,
     "grade_id": "cell-5fd96d17e21f469c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    # Reports various model metrics.  \n",
    "    pred = model.predict(X)        \n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8801571709233792,\n",
       " 'acc': 0.878,\n",
       " 'precision': 0.8732943469785575,\n",
       " 'recall': 0.8871287128712871}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test metrics.\n",
    "report_results(random_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7739604efa929d396b9cf11c0d8114a",
     "grade": false,
     "grade_id": "cell-a47ce46465ea41d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4 [5 points]\n",
    "\n",
    "Explain the overall procedure, and report the final result including which hyperparameter values were chosen. Make sure to explain your reasoning in choosing a refined parameter search space in **Part 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "651d32596f089e5e6a6cc978c6f79cd6",
     "grade": true,
     "grade_id": "cell-6fecb92ed6ad5abe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**(SOLUTION):**\n",
    "\n",
    "First we had to read the information in from the csv file and store it into our variables needed for training and testing ($X_{train}, y_{train})$, etc. Then after that we used our Vecotrizer function to create a dictionary with the words that we stored into our variable $X_{train}$ as the keys to that dictionary and how many times they showed up (frequency) as the Dictionary value. After doing that, we used Stratified-K-Fold to split up our data into 5 splits and make sure that we have equal amounts of the samples from each Class in the 5 splits. After doing this, we used the Grid Search to try and find the best parameter across different Kernel's. \n",
    "\n",
    "My results in doing this Grid Search yielded the best parameter as being $\\textbf{Linear Kernel}$ with a $C$ value of $0.01$, and a $CV$ score of $0.8745$. \n",
    "\n",
    "After this, we chose a refined paramater using a Randomized Search technique on the best parameter that we got which was the Linear Kernel and did it for large $C$ values. It ended up increasing our $CV$ score up to $0.877$!\n",
    "\n",
    "We ended up getting a final accuracy of about $87.8$% during the testing process shown above in the code which is not bad. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit [10 points] Advanced Hyperparameter Optimization\n",
    "While Grid Search and Random Search are tried and true methods for hyperparameter optimization, they are often very computationally expensive on larger models. Here you will explore a more advanced approach such as Bayesian Optimization or Tree-structured Parzen estimators (TPE). These algorithms are more complex, but there are packages that abstract away the complications. \n",
    "\n",
    "The general idea of these methods is to focus on the \"good\" areas of the hyperparameter space, and quickly rule out the bad areas. \n",
    "\n",
    "This extra credit is fairly open-ended, and meant to allow you to explore other hyperaparameter optimization methods outside the scikit-learn environment. Exploring this now will be **very helpful for your final project**. \n",
    "\n",
    "Here are some package recommendations:\n",
    "- [wandb](https://docs.wandb.com/): An alternative to TensorBoard. You can do hyperparameter optimization with sweeps. \n",
    "- [ray.tune](https://docs.ray.io/en/latest/tune/): Great package for large hyperparameter sweeps with great parallelization. The Hyperopt search algorithm is especially useful.\n",
    "\n",
    "Any package is okay, but **please make sure to leave an install command for us in the cell below so that we can install it automatically**.\n",
    "\n",
    "```python\n",
    "!pip install ray[tune]\n",
    "```\n",
    "\n",
    "The main criteria are that you use one of the following search algorithms (https://docs.ray.io/en/latest/tune/api_docs/suggestion.html):\n",
    "- Bayesian Optimization\n",
    "- Tree-structured Parzen estimators (TPE)\n",
    "- Adaptive TPE\n",
    "- Population Based Training (PBT)\n",
    "\n",
    "Additionally, you should optimize over the **course parameters** defined in part 2. However, instead of using a fixed categorical parameter space, you should choose ranges as follows.\n",
    "\n",
    "| Kenel| Parameter | space type | min | max |\n",
    "| --------- | ---------- | --- | --- | ---- |\n",
    "| Linear kernel | $C$ | log uniform | exp(-3) | exp(3)| \n",
    "| Polynomial kernel | degree| int uniform | 1 | 5| \n",
    "| Polynomial kernel | $\\gamma$ | uniform | 0.01 | 1 | \n",
    " RBF kernel | $\\gamma$ |  uniform | 0.01 | 1 | \n",
    "\n",
    "Fine-Tuning will be done automatically, which is the beauty of these methods, but make sure to run enough trials that you consistently score better than your previous solutions.\n",
    "\n",
    "We've laid out a template for using ray.tune and hyperopt, but feel free to change to a different package if you prefer.\n",
    "\n",
    "Note that when using a search algorithm like hyperopt, you should always wrap your algorithm in a `ConcurrencyLimiter` where the number of concurrent trials is a small fraction of the total number of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c2e2150b28fac9df924598ca3f956c5",
     "grade": true,
     "grade_id": "cell-a57fe1ccfaafef23",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# install package here\n",
    "# !pip install ray[tune] -q\n",
    "# !pip install hyperopt\n",
    "\n",
    "# import any packages here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from hyperopt import hp\n",
    "\n",
    "\n",
    "def objective(config):\n",
    "    \"\"\" \n",
    "        This is an objective function for ray.tune.\n",
    "    \"\"\"\n",
    "    \n",
    "    config=config['outer']\n",
    "    \n",
    "    # Now, train the SVM\n",
    "    model = get_pipeline(**config)\n",
    "    kfolds = get_kfolds()\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kfolds, scoring='accuracy')\n",
    "    tune.report(accuracy=score.mean())\n",
    "\n",
    "# TODO: Define the parameter space and your search algorithm \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Run ray.tune (make sure to play around with the number of trials. It's small here to get you going)\n",
    "analysis = tune.run(\n",
    "    objective, \n",
    "    search_alg=algo, \n",
    "    num_samples=32, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c64821dd5bd7e5fc2ce9fa4cf5c46be2",
     "grade": true,
     "grade_id": "cell-4d08aa9f1438168e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Report best parameters as before\n",
    "best_params = None\n",
    "best_score = None\n",
    " \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Report best parameters from hyperparameter optimization\n",
    "print(f'best params: {best_params} | best score: {best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional survey.\n",
    "***\n",
    "\n",
    "We are always interested in your feedback. At the end of each homework, there is a simple anonymous feedback [survey](https://docs.google.com/forms/d/e/1FAIpQLSe6yaRaEmShRe9DqYE66UA4PJtQTgkS6vloXyOKb7WuFFSYrQ/viewform?usp=pp_url) to solicit your feedback for how to improve the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
